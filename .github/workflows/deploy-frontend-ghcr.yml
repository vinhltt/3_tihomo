name: Deploy Frontend Service

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: false
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production
      force_rebuild:
        description: 'Force rebuild frontend image'
        required: false
        default: false
        type: boolean
      skip_backend_check:
        description: 'Skip backend dependency check'
        required: false
        default: false
        type: boolean
      force_recreate_env:
        description: 'Force recreate .env file even if it exists'
        required: false
        default: false
        type: boolean
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      force_rebuild:
        required: false
        type: boolean
        default: false
      skip_backend_check:
        required: false
        type: boolean
        default: false
      force_recreate_env:
        required: false
        type: boolean
        default: false

concurrency:
  group: tihomo-frontend-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  check-backend:
    if: ${{ !inputs.skip_backend_check }}
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    timeout-minutes: 5
    
    steps:
      - name: Setup SSH and check backend
        run: |
          sudo wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared
          sudo chmod +x /usr/local/bin/cloudflared
          
          mkdir -p "$HOME/.ssh"
          echo "Host truenas-cf-tunnel
            HostName ${{ secrets.TRUENAS_SSH_HOSTNAME_THROUGH_CLOUDFLARED }}
            ProxyCommand cloudflared access ssh --hostname %h
            User ${{ secrets.TRUENAS_USER }}
            StrictHostKeyChecking accept-new" > "$HOME/.ssh/config"
          chmod 600 "$HOME/.ssh/config"
        shell: bash

      - name: Add SSH key
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.TRUENAS_SSH_PRIVATE_KEY }}

      - name: Check backend readiness
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'EOF'
            DEPLOY_DIR="${{ vars.DEPLOY_PATH_ON_TRUENAS }}/deploy_${{ github.ref_name }}"
            echo "[INFO] Navigating to deployment directory: $DEPLOY_DIR"
            cd "$DEPLOY_DIR" || {
              echo "[ERROR] Cannot navigate to deployment directory: $DEPLOY_DIR"
              exit 1
            }
            
            echo "[INFO] Current directory: $(pwd)"
            echo "[INFO] Checking for docker-compose.yml: $(test -f docker-compose.yml && echo 'EXISTS' || echo 'MISSING')"
            
            # Check Docker permissions and set USE_SUDO appropriately
            if docker ps >/dev/null 2>&1; then
              USE_SUDO=""
              echo "[INFO] Docker accessible without sudo"
            else
              USE_SUDO="sudo"
              echo "[INFO] Docker requires sudo access"
            fi
            
            echo "[CHECK] Verifying backend services for frontend..."
            
            # Check if .env file exists and is readable
            if [ -f .env ]; then
              echo "[DEBUG] .env file exists, checking for corruption..."
              if ! grep -q "^[A-Z_][A-Z0-9_]*=" .env 2>/dev/null; then
                echo "[WARNING] .env file appears corrupted, removing it"
                rm -f .env
              fi
            fi
            
            REQUIRED_SERVICES=("ocelot-gateway")
            MISSING_SERVICES=()
            
            for service in "${REQUIRED_SERVICES[@]}"; do
              echo "[DEBUG] Checking service: $service"
              # Use --project-directory to avoid .env parsing issues
              if ! $USE_SUDO docker compose --project-directory . ps $service 2>/dev/null | grep -q "Up"; then
                echo "Warning:  Service $service is not running"
                MISSING_SERVICES+=("$service")
              else
                echo "[OK] Service $service is running"
              fi
            done
            
            if [ ${#MISSING_SERVICES[@]} -gt 0 ]; then
              echo "Error:  Missing backend services: ${MISSING_SERVICES[*]}"
              echo "[ACTION] Please run backend deployment first"
              echo "[DEBUG] Docker compose services status:"
              $USE_SUDO docker compose --project-directory . ps --format "table {{.Name}}\\t{{.Status}}" 2>/dev/null || echo "Failed to get services status"
              exit 1
            fi
            
            # Test API connectivity
            if $USE_SUDO docker compose --project-directory . exec -T ocelot-gateway curl -f http://localhost:8080/health >/dev/null 2>&1; then
              echo "[OK] Gateway is responsive"
            else
              echo "[WARNING] Gateway health check failed but container is running"
            fi
            
            echo "[OK] Backend services are ready for frontend deployment"
          EOF
        shell: bash

  deploy-frontend:
    runs-on: ubuntu-latest
    needs: [check-backend]
    if: always() && (needs.check-backend.result == 'success' || inputs.skip_backend_check)
    environment: ${{ inputs.environment }}
    timeout-minutes: 30
    
    steps:
      - name: "[1/9] Checkout code"
        uses: actions/checkout@v4

      - name: "[2/9] Setup environment"
        run: |
          # Clean project name - remove special characters and ensure lowercase
          CLEAN_ENV=$(echo "${{ inputs.environment }}" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]//g')
          echo "TRUENAS_DEPLOY_DIR=${{ vars.DEPLOY_PATH_ON_TRUENAS }}/deploy_${GITHUB_REF_NAME}" >> $GITHUB_ENV
          echo "COMPOSE_PROJECT_NAME=tihomo_${CLEAN_ENV}" >> $GITHUB_ENV
          echo "[INFO] Environment: '${{ inputs.environment }}' ‚Üí cleaned: '${CLEAN_ENV}'"
        shell: bash

      - name: "[3/9] Setup SSH"
        run: |
          sudo wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared
          sudo chmod +x /usr/local/bin/cloudflared
          
          mkdir -p "$HOME/.ssh"
          echo "Host truenas-cf-tunnel
            HostName ${{ secrets.TRUENAS_SSH_HOSTNAME_THROUGH_CLOUDFLARED }}
            ProxyCommand cloudflared access ssh --hostname %h
            User ${{ secrets.TRUENAS_USER }}
            StrictHostKeyChecking accept-new" > "$HOME/.ssh/config"
          chmod 600 "$HOME/.ssh/config"
        shell: bash

      - name: "[4/9] Add SSH key"
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.TRUENAS_SSH_PRIVATE_KEY }}

      - name: "[4.5/9] Prepare deployment directory for GHCR"
        run: |
          # Set deployment directory outside SSH session to ensure proper expansion
          DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
          
          # First, sync docker-compose.ghcr.yml to TrueNAS if needed
          echo "[SYNC] Ensuring docker-compose.ghcr.yml exists on TrueNAS..."
          rsync -rltvz --safe-links \
            --chmod=Du=rwx,Dgo=rx,Fu=rw,Fgo=r \
            --no-perms --no-owner --no-group \
            --progress \
            -e "ssh -F $HOME/.ssh/config -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=30" \
            $GITHUB_WORKSPACE/docker-compose.ghcr.yml \
            truenas-cf-tunnel:"$DEPLOY_DIR/docker-compose.ghcr.yml"
          
          echo "[SYNC] Rsync completed, waiting for filesystem sync..."
          sleep 3
          
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'EOF'
            echo "[PREP] Preparing deployment directory for GHCR deployment..."
            
            # Use deployment directory passed from GitHub Actions
            DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
            
            echo "[DEBUG] Target deployment directory: $DEPLOY_DIR"
            echo "[DEBUG] Current working directory: $(pwd)"
            
            # Create required directories with proper ownership
            mkdir -p "$DEPLOY_DIR"
            mkdir -p "$DEPLOY_DIR/.rsync-partial"
            
            # Navigate to deployment directory
            cd "$DEPLOY_DIR" || {
              echo "[ERROR] Cannot navigate to deployment directory: $DEPLOY_DIR"
              exit 1
            }
            
            echo "[DEBUG] Now in directory: $(pwd)"
            echo "[DEBUG] Directory contents before verification:"
            ls -la
            
            # Set proper permissions and ownership
            chmod 755 "$DEPLOY_DIR"
            chmod -R 755 "$DEPLOY_DIR/.rsync-partial" 2>/dev/null || true
            
            # Fix ownership to current user to avoid permission issues
            chown -R $(whoami):$(whoami) "$DEPLOY_DIR" 2>/dev/null || true
            
            # Fix ownership of entire deployment directory
            if command -v sudo >/dev/null 2>&1; then
              sudo chown -R $(whoami):$(whoami) "$DEPLOY_DIR" 2>/dev/null || true
              sudo chmod -R 755 "$DEPLOY_DIR" 2>/dev/null || true
            else
              chown -R $(whoami):$(whoami) "$DEPLOY_DIR" 2>/dev/null || true
              chmod -R 755 "$DEPLOY_DIR" 2>/dev/null || true
            fi
            
            echo "[OK] GHCR deployment directory prepared with proper permissions"
            
            # Verify docker-compose.ghcr.yml exists
            echo "[DEBUG] Checking for docker-compose.ghcr.yml in: $(pwd)"
            if [ -f docker-compose.ghcr.yml ]; then
              echo "[OK] docker-compose.ghcr.yml confirmed on TrueNAS"
              echo "[DEBUG] File size: $(ls -lh docker-compose.ghcr.yml | awk '{print $5}')"
            else
              echo "[ERROR] docker-compose.ghcr.yml still missing after sync"
              echo "[DEBUG] Files in current directory:"
              ls -la
              echo "[DEBUG] Searching for docker-compose files:"
              find . -name "*docker-compose*" -type f 2>/dev/null || echo "No docker-compose files found"
              exit 1
            fi
          EOF
        shell: bash

      - name: "[5/9] Verify GHCR deployment configuration"
        run: |
          echo "[VERIFY] Checking GHCR deployment configuration on TrueNAS..."
          DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
          
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'EOF'
            DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
            cd "$DEPLOY_DIR"
            
            echo "[INFO] Verifying GHCR compose file exists..."
            if [ ! -f docker-compose.ghcr.yml ]; then
              echo "[ERROR] docker-compose.ghcr.yml not found on TrueNAS"
              echo "[INFO] Please ensure docker-compose.ghcr.yml exists in deployment directory"
              echo "[DEBUG] Current directory structure:"
              ls -la
              exit 1
            fi
            
            echo "[OK] docker-compose.ghcr.yml found"
            echo "[INFO] GHCR deployment ready - using pre-built images from registry"
            echo "[DEBUG] Using compose file: docker-compose.ghcr.yml"
          EOF
        shell: bash

      - name: "[6/9] Check and create environment file if needed"
        run: |
          # Set deployment directory outside SSH session to ensure proper expansion
          DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
          
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'EOF'
            # Use deployment directory passed from GitHub Actions
            DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
            
            echo "[INFO] Navigating to deployment directory: $DEPLOY_DIR"
            mkdir -p "$DEPLOY_DIR"
            cd "$DEPLOY_DIR" || {
              echo "[ERROR] Cannot navigate to deployment directory: $DEPLOY_DIR"
              echo "[DEBUG] Current working directory: $(pwd)"
              echo "[DEBUG] Directory listing:"
              ls -la
              exit 1
            }
            
            echo "[INFO] Working in directory: $(pwd)"
            
            # Ensure directory has proper permissions for writing files
            chmod 755 "$(pwd)"
            
            # Check if force recreate is requested
            if [ "${{ inputs.force_recreate_env }}" = "true" ]; then
              echo "[FORCE] Force recreate .env requested, removing existing file..."
              rm -f .env
              echo "[INFO] Creating new comprehensive .env file..."
            elif [ -f .env ]; then
              echo "[CHECK] .env file exists, validating comprehensive variables..."
              
              # Check if .env file has comprehensive variables including Nuxt config
              required_vars="COMPOSE_PROJECT_NAME NODE_ENV API_BASE_URL NUXT_HOST NUXT_PORT"
              missing_vars=""
              
              for var in $required_vars; do
                if ! grep -q "^${var}=" .env; then
                  missing_vars="$missing_vars $var"
                fi
              done
              
              if [ -z "$missing_vars" ]; then
                echo "[OK] Existing .env file has comprehensive configuration"
                echo "[INFO] Skipping .env creation - using existing comprehensive file"
                echo "[DEBUG] .env file content (first 10 lines):"
                head -10 .env
                echo "[INFO] Frontend environment setup completed"
                exit 0
              else
                echo "[WARNING] .env file exists but missing comprehensive variables: $missing_vars"
                echo "[ACTION] Recreating comprehensive .env file..."
                rm -f .env
              fi
            else
              echo "[INFO] No .env file found, creating new comprehensive one..."
            fi
            
            echo "[CREATE] Creating comprehensive .env file for frontend deployment..."
            
            # Create .env file using direct echo commands to avoid SSH heredoc parsing issues
            rm -f .env
            
            # CORS Configuration
            echo "# ================================" >> .env
            echo "# CORS Configuration" >> .env
            echo "# ================================" >> .env
            echo "CORS_POLICY_NAME=DefaultCorsPolicy" >> .env
            # Set CORS origins based on environment
            echo "CORS_ALLOWED_ORIGINS_0='${{ vars.CORS_ALLOWED_ORIGINS_0 || '*' }}'" >> .env
            echo "CORS_ALLOWED_ORIGINS_1='${{ vars.CORS_ALLOWED_ORIGINS_1 }}'" >> .env
            echo "CORS_ALLOWED_ORIGINS_2='${{ vars.CORS_ALLOWED_ORIGINS_2 }}'" >> .env
            echo "CORS_ALLOWED_ORIGINS_3='${{ vars.CORS_ALLOWED_ORIGINS_3 }}'" >> .env
            echo "CORS_ALLOWED_METHODS_0='${{ vars.CORS_ALLOWED_METHODS_0 || 'GET' }}'" >> .env
            echo "CORS_ALLOWED_METHODS_1='${{ vars.CORS_ALLOWED_METHODS_1 || 'POST' }}'" >> .env
            echo "CORS_ALLOWED_METHODS_2='${{ vars.CORS_ALLOWED_METHODS_2 || 'PUT' }}'" >> .env
            echo "CORS_ALLOWED_METHODS_3='${{ vars.CORS_ALLOWED_METHODS_3 || 'DELETE' }}'" >> .env
            echo "CORS_ALLOWED_METHODS_4='${{ vars.CORS_ALLOWED_METHODS_4 || 'OPTIONS' }}'" >> .env
            echo "CORS_ALLOWED_HEADERS='*'" >> .env
            echo "CORS_EXPOSED_HEADERS='${{ vars.CORS_EXPOSED_HEADERS || 'Token-Expired'}}'" >> .env
            echo "CORS_PREFLIGHT_MAX_AGE='10'" >> .env
            echo "CORS_ALLOW_CREDENTIALS='true'" >> .env
            echo "CORS_ALLOWED_HEADERS='*'" >> .env
            echo "CORS_EXPOSED_HEADERS='Token-Expired'" >> .env
            echo "CORS_PREFLIGHT_MAX_AGE='10'" >> .env
            echo "CORS_ALLOW_CREDENTIALS='true'" >> .env
            echo "" >> .env
            
            # Environment Configuration
            echo "# ================================" >> .env
            echo "# Environment Configuration" >> .env
            echo "# ================================" >> .env
            echo "ASPNETCORE_ENVIRONMENT=Docker" >> .env
            echo "" >> .env
            
            # Database Configuration
            echo "# ================================" >> .env
            echo "# Database Configuration" >> .env
            echo "# ================================" >> .env
            echo "# Identity Database" >> .env
            echo "IDENTITY_DB_USERNAME='${{ vars.IDENTITY_DB_USERNAME || 'identity_user' }}'" >> .env
            echo "IDENTITY_DB_PASSWORD='${{ secrets.IDENTITY_DB_PASSWORD || 'temp_password' }}'" >> .env  
            echo "IDENTITY_DB_PORT='${{ vars.IDENTITY_DB_PORT || '5431' }}'" >> .env
            echo "COREFINANCE_DB_USERNAME='${{ vars.COREFINANCE_DB_USERNAME || 'corefinance_user' }}'" >> .env
            echo "COREFINANCE_DB_PASSWORD='${{ secrets.COREFINANCE_DB_PASSWORD || 'temp_password' }}'" >> .env
            echo "COREFINANCE_DB_PORT='${{ vars.COREFINANCE_DB_PORT || '5432' }}'" >> .env
            echo "MONEYMANAGEMENT_DB_USERNAME='${{ vars.MONEYMANAGEMENT_DB_USERNAME || 'money_user' }}'" >> .env
            echo "MONEYMANAGEMENT_DB_PASSWORD='${{ secrets.MONEYMANAGEMENT_DB_PASSWORD || 'temp_password' }}'" >> .env
            echo "MONEYMANAGEMENT_DB_PORT='${{ vars.MONEYMANAGEMENT_DB_PORT || '5433' }}'" >> .env
            echo "PLANNINGINVESTMENT_DB_USERNAME='${{ vars.PLANNINGINVESTMENT_DB_USERNAME || 'planning_user' }}'" >> .env
            echo "PLANNINGINVESTMENT_DB_PASSWORD='${{ secrets.PLANNINGINVESTMENT_DB_PASSWORD || 'temp_password' }}'" >> .env
            echo "PLANNINGINVESTMENT_DB_PORT='${{ vars.PLANNINGINVESTMENT_DB_PORT || '5434' }}'" >> .env
            echo "REPORTING_DB_USERNAME='${{ vars.REPORTING_DB_USERNAME || 'reporting_user' }}'" >> .env
            echo "REPORTING_DB_PASSWORD='${{ secrets.REPORTING_DB_PASSWORD || 'temp_password' }}'" >> .env
            echo "REPORTING_DB_PORT='${{ vars.REPORTING_DB_PORT || '5435' }}'" >> .env

            # Add authentication configuration  
            echo "" >> .env
            echo "# Authentication Configuration" >> .env
            echo "JWT_SECRET_KEY='${{ secrets.JWT_SECRET_KEY || 'temp_jwt_secret_key_123456789' }}'" >> .env
            echo "JWT_ISSUER='${{ vars.JWT_ISSUER || 'TiHoMo' }}'" >> .env
            echo "JWT_AUDIENCE_IDENTITY_API='${{ vars.JWT_AUDIENCE_IDENTITY_API || 'TiHoMo.Identity.Api' }}'" >> .env
            echo "JWT_AUDIENCE_COREFINANCE_API='${{ vars.JWT_AUDIENCE_COREFINANCE_API || 'TiHoMo.CoreFinance.Api' }}'" >> .env
            echo "JWT_AUDIENCE_EXCEL_API='${{ vars.JWT_AUDIENCE_EXCEL_API || 'TiHoMo.Excel.Api' }}'" >> .env
            echo "JWT_AUDIENCE_FRONTEND='${{ vars.JWT_AUDIENCE_FRONTEND || 'TiHoMo.Frontend' }}'" >> .env
            echo "JWT_AUDIENCE_OCELOT_GATEWAY='${{ vars.JWT_AUDIENCE_OCELOT_GATEWAY || 'TiHoMo.Gateway' }}'" >> .env

            # Add external services configuration
            echo "" >> .env
            echo "# External Services Configuration" >> .env
            echo "REDIS_PASSWORD='${{ secrets.REDIS_PASSWORD || 'temp_redis_password' }}'" >> .env
            echo "REDIS_PORT='${{ vars.REDIS_PORT || '6379' }}'" >> .env
            echo "RABBITMQ_PASSWORD='${{ secrets.RABBITMQ_PASSWORD || 'temp_rabbitmq_password' }}'" >> .env
            echo "RABBITMQ_PORT='${{ vars.RABBITMQ_PORT || '5672' }}'" >> .env
            echo "RABBITMQ_MANAGEMENT_PORT='${{ vars.RABBITMQ_MANAGEMENT_PORT || '15672' }}'" >> .env
            echo "PROMETHEUS_PORT='${{ vars.PROMETHEUS_PORT || '9090' }}'" >> .env
            echo "GRAFANA_PORT='${{ vars.GRAFANA_PORT || '3000' }}'" >> .env
            echo "GRAFANA_ADMIN_PASSWORD='${{ secrets.GRAFANA_ADMIN_PASSWORD || 'temp_grafana_password' }}'" >> .env
            echo "MAILHOG_SMTP_PORT='${{ vars.MAILHOG_SMTP_PORT || '1025' }}'" >> .env
            echo "MAILHOG_UI_PORT='${{ vars.MAILHOG_UI_PORT || '8025' }}'" >> .env
            echo "GATEWAY_PORT='${{ vars.GATEWAY_PORT || '8080' }}'" >> .env

            # Add API ports configuration
            echo "" >> .env
            echo "# API Ports Configuration" >> .env
            echo "API_GATEWAY_PORT='${{ vars.API_GATEWAY_PORT || '8080' }}'" >> .env
            echo "IDENTITY_API_PORT='${{ vars.IDENTITY_API_PORT || '5217' }}'" >> .env
            echo "COREFINANCE_API_PORT='${{ vars.COREFINANCE_API_PORT || '7293' }}'" >> .env
            echo "EXCEL_API_PORT='${{ vars.EXCEL_API_PORT || '5219' }}'" >> .env
            echo "FRONTEND_PORT='${{ vars.FRONTEND_PORT || '3500' }}'" >> .env

            # Add Docker and frontend configuration
            echo "" >> .env
            echo "# Docker Build Configuration" >> .env
            echo "NUXT_BUILD_TARGET=production" >> .env
            echo "NODE_ENV=production" >> .env
            echo "DOCKER_USER=1001:1001" >> .env
            echo "NUXT_DEV_SSR=false" >> .env
            echo "NUXT_DEV_TOOLS=false" >> .env
            echo "NUXT_DEBUG=false" >> .env
            echo "" >> .env
            echo "# Frontend Configuration" >> .env
            echo "PUBLIC_API_BASE_URL='${{ vars.PUBLIC_API_BASE_URL || 'http://ocelot-gateway:8080' }}'" >> .env
            echo "FRONTEND_BASE_URL='${{ vars.FRONTEND_BASE_URL || 'http://localhost:3500' }}'" >> .env
            echo "APP_PUBLIC_GOOGLE_CLIENT_ID='${{ vars.APP_PUBLIC_GOOGLE_CLIENT_ID || '' }}'" >> .env

            # Frontend Authentication & OAuth Configuration
            echo "" >> .env
            echo "# Frontend Authentication Configuration" >> .env
            echo "JWT_SECRET_KEY='${{ secrets.JWT_SECRET_KEY || 'temp_jwt_secret_key_123456789' }}'" >> .env
            echo "OAUTH_GOOGLE_CLIENT_ID='${{ vars.APP_PUBLIC_GOOGLE_CLIENT_ID || '' }}'" >> .env
            echo "OAUTH_REDIRECT_URI='${{ vars.FRONTEND_BASE_URL || 'http://localhost:3500' }}/auth/callback'" >> .env

            # Set frontend image tag based on branch
            if [ "${{ github.ref_name }}" = "main" ]; then
              echo "FRONTEND_IMAGE_TAG='latest'" >> .env
            else
              echo "FRONTEND_IMAGE_TAG='${{ github.ref_name }}'" >> .env
            fi

            # Add infrastructure configuration
            echo "" >> .env
            echo "# Infrastructure Configuration" >> .env
            echo "PGADMIN_PASSWORD='${{ secrets.PGADMIN_PASSWORD || 'temp_pgadmin_password' }}'" >> .env
            echo "PGADMIN_PORT='${{ vars.PGADMIN_PORT || '8080' }}'" >> .env
            echo "LOKI_PORT='${{ vars.LOKI_PORT || '3100' }}'" >> .env
            echo "NGINX_HTTP_PORT='${{ vars.NGINX_HTTP_PORT || '80' }}'" >> .env
            echo "NGINX_HTTPS_PORT='${{ vars.NGINX_HTTPS_PORT || '443' }}'" >> .env

            # Add network and project configuration
            echo "" >> .env
            echo "# Network Configuration" >> .env
            echo "DOCKER_NETWORK_SUBNET='${{ vars.DOCKER_NETWORK_SUBNET || '172.20.0.0/16' }}'" >> .env
            echo "" >> .env
            echo "# Docker Compose Project Name" >> .env
            echo "COMPOSE_PROJECT_NAME='${{ env.COMPOSE_PROJECT_NAME }}'" >> .env

            echo "[OK] Comprehensive .env file created successfully"
            
            # Display first few lines for verification (without sensitive data)
            echo "[VERIFY] .env file content (first 20 lines):"
            head -20 .env
            
            echo "[INFO] Frontend environment setup completed"
          EOF
        shell: bash

      - name: "[7/9] Deploy frontend with complete cleanup and rebuild"
        run: |
          # Set deployment directory outside SSH session to ensure proper expansion
          DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
          
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'EOF'
            set -e
            # Use deployment directory passed from GitHub Actions
            DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
            cd $DEPLOY_DIR
            
            # Verify that comprehensive .env file exists from step 6
            if [ ! -f .env ]; then
              echo "[ERROR] No .env file found - step 6 should have created comprehensive .env"
              echo "[DEBUG] Current directory contents:"
              ls -la
              exit 1
            fi
            
            echo "[INFO] Using comprehensive .env file created in step 6"
            echo "[DEBUG] .env file size: $(wc -l < .env) lines"
            
            # Check Docker permissions and set USE_SUDO appropriately
            if docker ps >/dev/null 2>&1; then
              USE_SUDO=""
              echo "[INFO] Docker accessible without sudo"
            else
              USE_SUDO="sudo"
              echo "[INFO] Docker requires sudo access"
            fi
            
            echo "[FRONTEND] Starting comprehensive frontend deployment..."
            
            # Step 1: Stop and remove existing frontend containers
            echo "[CLEANUP] Stopping and removing existing frontend containers..."
            if $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt | grep -q "Up"; then
              echo "[INFO] Frontend is currently running, performing graceful shutdown..."
              $USE_SUDO docker compose -f docker-compose.ghcr.yml stop frontend-nuxt
              sleep 3
            fi
            
            # Remove containers
            echo "[CLEANUP] Removing frontend containers..."
            $USE_SUDO docker compose -f docker-compose.ghcr.yml rm -f frontend-nuxt 2>/dev/null || true
            
            # Step 2: Clean up Docker images and system
            echo "[CLEANUP] Cleaning up Docker images and system..."
            
            # Additional cleanup (containers should already be stopped above)
            
            # Remove old frontend images
            OLD_IMAGES=$($USE_SUDO docker images | grep "tihomo.*frontend" | awk '{print $3}' || true)
            if [ ! -z "$OLD_IMAGES" ]; then
              echo "[CLEANUP] Removing old frontend images..."
              echo "$OLD_IMAGES" | xargs -r $USE_SUDO docker rmi -f 2>/dev/null || true
            fi
            
            # Clean up dangling images and volumes (but not networks)
            $USE_SUDO docker image prune -f 2>/dev/null || true
            $USE_SUDO docker volume prune -f 2>/dev/null || true
            
            # Step 3: Pull latest frontend image from GHCR
            echo "[PULL] Pulling latest frontend image from GHCR for ${{ inputs.environment }} environment..."
            
            # Set image tag based on branch
            if [ "${{ github.ref_name }}" = "main" ]; then
              IMAGE_TAG="latest"
            else
              IMAGE_TAG="${{ github.ref_name }}"
            fi
            
            echo "[PULL] Using image tag: $IMAGE_TAG"
            
            # Pull latest image from GHCR with retry and authentication fallback
            pull_attempts=0
            max_pull_attempts=3
            
            while [ $pull_attempts -lt $max_pull_attempts ]; do
              echo "[PULL] Pull attempt $((pull_attempts + 1))/$max_pull_attempts..."
              
              # Try pulling with different strategies
              if [ $pull_attempts -eq 0 ]; then
                # First attempt: Direct pull
                echo "[PULL] Attempting direct pull from GHCR..."
                PULL_CMD="$USE_SUDO docker pull ghcr.io/${{ github.repository }}/frontend-nuxt:$IMAGE_TAG"
              elif [ $pull_attempts -eq 1 ]; then
                # Second attempt: Try with --platform to avoid manifest issues
                echo "[PULL] Attempting pull with platform specification..."
                PULL_CMD="$USE_SUDO docker pull --platform linux/amd64 ghcr.io/${{ github.repository }}/frontend-nuxt:$IMAGE_TAG"
              else
                # Third attempt: Fallback to local build if available
                echo "[PULL] GHCR authentication failed, attempting local build fallback..."
                if [ -f docker-compose.ghcr.yml ]; then
                  PULL_CMD="$USE_SUDO docker compose -f docker-compose.ghcr.yml build frontend-nuxt"
                else
                  echo "[ERROR] No fallback build option available"
                  break
                fi
              fi
              
              if eval "$PULL_CMD"; then
                echo "[PULL] Image pull/build successful on attempt $((pull_attempts + 1))"
                break
              else
                pull_attempts=$((pull_attempts + 1))
                if [ $pull_attempts -lt $max_pull_attempts ]; then
                  echo "[PULL] Pull failed, retrying in 30 seconds..."
                  echo "[DEBUG] Error was likely GHCR authentication or manifest issue"
                  sleep 30
                  # Clean up any partial images
                  $USE_SUDO docker system prune -f 2>/dev/null || true
                else
                  echo "[PULL] All pull attempts failed after $max_pull_attempts tries"
                  echo "[ERROR] Cannot pull/build frontend image"
                  echo "[INFO] Available images:"
                  $USE_SUDO docker images | grep -E "(frontend|nuxt)" || echo "No frontend images found"
                  echo "[SOLUTION] Either:"
                  echo "  1. Make GHCR package public at: https://github.com/${{ github.repository }}/pkgs/container/3_tihomo%2Ffrontend-nuxt"
                  echo "  2. Setup GHCR authentication on TrueNAS with GitHub token"
                  echo "  3. Use local build fallback with build context"
                  exit 1
                fi
              fi
            done
            
            echo "[PULL] Frontend image pulled successfully from GHCR"
            
            # Step 4: Deploy frontend with enhanced monitoring
            echo "[DEPLOY] Starting frontend service with GHCR images..."
            $USE_SUDO docker compose -f docker-compose.ghcr.yml up -d --no-deps --force-recreate frontend-nuxt
            
            # Step 5: Enhanced health check with better error reporting
            echo "[HEALTH] Starting enhanced health check process..."
            max_attempts=5
            attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              echo "[HEALTH] Health check attempt $attempt/$max_attempts..."
              
              # Check if container is running
              if $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt | grep -q "Up"; then
                echo "[OK] Frontend container is running"
                
                # Wait for Nuxt to initialize properly
                echo "[WAIT] Waiting for Nuxt application to initialize (60 seconds)..."
                sleep 60
                
                # Test HTTP response
                if $USE_SUDO docker compose -f docker-compose.ghcr.yml exec -T frontend-nuxt curl -f http://localhost:3000/ >/dev/null 2>&1; then
                  echo "[SUCCESS] ‚úÖ Frontend is responding to HTTP requests!"
                  break
                elif $USE_SUDO docker compose -f docker-compose.ghcr.yml exec -T frontend-nuxt curl -s http://localhost:3000/ | grep -q "html\|HTML"; then
                  echo "[SUCCESS] ‚úÖ Frontend is serving content (HTTP 200)!"
                  break
                else
                  echo "[WAIT] Frontend not ready yet (attempt $attempt/$max_attempts)"
                  
                  # Show logs every 5 attempts for debugging
                  if [ $(($attempt % 5)) -eq 0 ]; then
                    echo "[DEBUG] Recent frontend logs (attempt $attempt):"
                    $USE_SUDO docker compose -f docker-compose.ghcr.yml logs --tail=15 frontend-nuxt
                    echo "[DEBUG] Container status:"
                    $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt
                  fi
                  
                  sleep 10
                  ((attempt++))
                fi
              else
                echo "[ERROR] Frontend container not running (attempt $attempt/$max_attempts)"
                
                # Show container status and logs for debugging
                echo "[DEBUG] Container status:"
                $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt
                echo "[DEBUG] Recent logs:"
                $USE_SUDO docker compose -f docker-compose.ghcr.yml logs --tail=10 frontend-nuxt
                
                sleep 5
                ((attempt++))
              fi
            done
            
            # Final error handling
            if [ $attempt -gt $max_attempts ]; then
              echo "[ERROR] ‚ùå Frontend failed to start after $max_attempts attempts"
              echo "[DEBUG] Complete troubleshooting information:"
              echo "=============================================="
              echo "[DEBUG] Container status:"
              $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt
              echo "=============================================="
              echo "[DEBUG] Last 50 lines of frontend logs:"
              $USE_SUDO docker compose -f docker-compose.ghcr.yml logs --tail=50 frontend-nuxt
              echo "=============================================="
              echo "[DEBUG] Docker system info:"
              $USE_SUDO docker system df
              echo "=============================================="
              echo "[DEBUG] Available images:"
              $USE_SUDO docker images | grep -E "(frontend|nuxt|tihomo)" || echo "No matching images found"
              echo "=============================================="
              exit 1
            fi
            
            echo "[SUCCESS] Frontend deployed successfully"
            
            # Show final status
            echo "[STATUS] Frontend service status:"
            $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt
            
            # Show recent logs for verification
            echo "[LOGS] Recent frontend logs:"
            $USE_SUDO docker compose -f docker-compose.ghcr.yml logs --tail=10 frontend-nuxt
          EOF
        shell: bash

      - name: "[8/9] Final health check and notification"
        run: |
          # Set deployment directory outside SSH session to ensure proper expansion
          DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
          
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel /bin/bash << 'REMOTE_EOF'
            # Use deployment directory passed from GitHub Actions
            DEPLOY_DIR="${{ env.TRUENAS_DEPLOY_DIR }}"
            cd $DEPLOY_DIR
            
            # Check Docker permissions and set USE_SUDO appropriately
            if docker ps >/dev/null 2>&1; then
              USE_SUDO=""
              echo "[INFO] Docker accessible without sudo"
            else
              USE_SUDO="sudo"
              echo "[INFO] Docker requires sudo access"
            fi
            
            echo "[HEALTH] Final frontend health check..."
            
            # Check container status
            if $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt | grep -q "Up"; then
              echo "[OK] Frontend container is running"
              
              # Check HTTP response
              if $USE_SUDO docker compose -f docker-compose.ghcr.yml exec -T frontend-nuxt curl -f http://localhost:3000/ >/dev/null 2>&1; then
                echo "[OK] Frontend is serving HTTP requests"
                
                # Check API connectivity from frontend
                if $USE_SUDO docker compose -f docker-compose.ghcr.yml exec -T frontend-nuxt curl -f http://ocelot-gateway:8080/health >/dev/null 2>&1; then
                  echo "[OK] Frontend can connect to backend gateway"
                else
                  echo "[WARNING] Frontend cannot connect to backend gateway"
                fi
                
                echo "[SUCCESS] Frontend health check passed"
              else
                echo "[WARNING] Frontend HTTP check failed, but container is running"
                echo "[DEBUG] Recent frontend logs:"
                $USE_SUDO docker compose -f docker-compose.ghcr.yml logs --tail=20 frontend-nuxt
              fi
            else
              echo "[ERROR] Frontend container is not running"
              $USE_SUDO docker compose -f docker-compose.ghcr.yml ps frontend-nuxt
              exit 1
            fi
            
            echo "[INFO] Full system status:"
            $USE_SUDO docker compose -f docker-compose.ghcr.yml ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
          REMOTE_EOF
          
          # Send Discord notification
          webhook_url="${{ secrets.DISCORD_WEBHOOK_URL }}"
          if [ -n "$webhook_url" ]; then
            curl -H "Content-Type: application/json" \
                 -d '{
                   "content": "‚úÖ **Frontend Deployment SUCCESS**\n\nüìä **Info:**\n‚Ä¢ **Environment:** `${{ inputs.environment }}`\n‚Ä¢ **Branch:** `${{ github.ref_name }}`\n‚Ä¢ **Force Rebuild:** `${{ inputs.force_rebuild }}`\n‚Ä¢ **Frontend URL:** `http://<TRUENAS_IP>:3500`\n\nüöÄ **Frontend is ready and serving requests**"
                 }' \
                 "$webhook_url" || echo "Discord notification failed"
          fi
        shell: bash

      - name: "[9/9] Send failure notification"
        if: failure()
        uses: appleboy/discord-action@v1.2.0
        with:
          webhook_url: ${{ secrets.DISCORD_WEBHOOK_URL }}
          message: |
            ‚ùå **Frontend Deployment FAILED**
            
            üìä **Deployment Info:**
            ‚Ä¢ **Environment:** `${{ inputs.environment }}`
            ‚Ä¢ **Branch:** `${{ github.ref_name }}`
            ‚Ä¢ **Force Rebuild:** `${{ inputs.force_rebuild }}`
            ‚Ä¢ **Status:** `FAILED`
            
            üö® **Frontend deployment issues - check logs for details**
            
            [üìã View Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})