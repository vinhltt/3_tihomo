name: Auto Deploy TiHoMo to TrueNAS

on:
  workflow_dispatch:
    # Cho phép kích hoạt thủ công với tùy chọn environment
    inputs:
      environment:
        description: 'Deployment environment'
        required: false
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production
      skip_health_checks:
        description: 'Skip health checks (for testing)'
        required: false
        default: false
        type: boolean
      force_rebuild:
        description: 'Force rebuild all images (no cache)'
        required: false
        default: false
        type: boolean
  push:
    branches: [ master, develop ]

# Chia group concurrency theo từng branch (mỗi branch sẽ có hàng đợi riêng)
# Nếu có workflow mới trên cùng một branch, workflow cũ sẽ bị cancel, chỉ giữ lại workflow mới nhất
concurrency:
  group: tihomo-deploy-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest # Sử dụng GitHub-hosted runner
    environment: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || github.ref_name == 'staging' && 'staging' || 'development') }}
    # Đặt thời gian timeout cho toàn bộ job này là 30 phút
    timeout-minutes: 30 
    steps:
      - name: "[1/18] Checkout code"
        uses: actions/checkout@v4

      - name: "[2/18] Enhanced validation of secrets and environment variables"
        run: |
          echo "[CHECK] Kiểm tra comprehensive validation của các secrets và variables..."
          
          # Function to validate password strength
          validate_password_strength() {
            local password="$1"
            local name="$2"
            local min_length=12
            
            if [ ${#password} -lt $min_length ]; then
              echo "[ERROR] $name: Mật khẩu quá ngắn (tối thiểu $min_length ký tự, hiện tại: ${#password})"
              return 1
            fi
            
            # Check for basic complexity
            if [[ ! "$password" =~ [A-Z] ]] || [[ ! "$password" =~ [a-z] ]] || [[ ! "$password" =~ [0-9] ]]; then
              echo "[WARNING] $name: Mật khẩu nên có chữ hoa, chữ thường và số"
            fi
            
            echo "[OK] $name: Độ dài ${#password} ký tự - đạt yêu cầu"
            return 0
          }
          
          # Function to validate JWT secret
          validate_jwt_secret() {
            local jwt_secret="$1"
            local min_length=32
            
            if [ -z "$jwt_secret" ]; then
              echo "[ERROR] JWT_SECRET_KEY: Không được để trống"
              return 1
            fi
            
            if [ ${#jwt_secret} -lt $min_length ]; then
              echo "[ERROR] JWT_SECRET_KEY: Quá ngắn (tối thiểu $min_length ký tự, hiện tại: ${#jwt_secret})"
              return 1
            fi
            
            # Check for base64 or hex format
            if [[ "$jwt_secret" =~ ^[A-Za-z0-9+/=]+$ ]] || [[ "$jwt_secret" =~ ^[A-Fa-f0-9]+$ ]]; then
              echo "[OK] JWT_SECRET_KEY: Format hợp lệ (độ dài: ${#jwt_secret} ký tự)"
            else
              echo "[WARNING] JWT_SECRET_KEY: Nên sử dụng format base64 hoặc hex để tăng độ bảo mật"
            fi
            
            return 0
          }
          
          # Function to validate port numbers
          validate_port() {
            local port="$1"
            local name="$2"
            
            if ! [[ "$port" =~ ^[0-9]+$ ]] || [ "$port" -lt 1 ] || [ "$port" -gt 65535 ]; then
              echo "[ERROR] $name: Port không hợp lệ ($port)"
              return 1
            fi
            
            # Check for common conflicting ports
            case $port in
              22|80|443|3000|5000|8080|8443)
                echo "[WARNING] $name: Port $port có thể xung đột với services khác"
                ;;
            esac
            
            echo "[OK] $name: Port $port hợp lệ"
            return 0
          }
          
          # Kiểm tra các secrets quan trọng
          MISSING_SECRETS=()
          VALIDATION_FAILED=false
          
          # JWT Secret validation
          if [ -z "${{ secrets.JWT_SECRET_KEY }}" ]; then
            MISSING_SECRETS+=("JWT_SECRET_KEY")
            VALIDATION_FAILED=true
          else
            validate_jwt_secret "${{ secrets.JWT_SECRET_KEY }}" || VALIDATION_FAILED=true
          fi
          
          # Database password validation
          if [ -z "${{ secrets.IDENTITY_DB_PASSWORD }}" ]; then
            MISSING_SECRETS+=("IDENTITY_DB_PASSWORD")
            VALIDATION_FAILED=true
          else
            validate_password_strength "${{ secrets.IDENTITY_DB_PASSWORD }}" "IDENTITY_DB_PASSWORD" || VALIDATION_FAILED=true
          fi
          
          if [ -z "${{ secrets.COREFINANCE_DB_PASSWORD }}" ]; then
            MISSING_SECRETS+=("COREFINANCE_DB_PASSWORD")
            VALIDATION_FAILED=true
          else
            validate_password_strength "${{ secrets.COREFINANCE_DB_PASSWORD }}" "COREFINANCE_DB_PASSWORD" || VALIDATION_FAILED=true
          fi
          
          # Redis password validation
          if [ -z "${{ secrets.REDIS_PASSWORD }}" ]; then
            MISSING_SECRETS+=("REDIS_PASSWORD")
            VALIDATION_FAILED=true
          else
            validate_password_strength "${{ secrets.REDIS_PASSWORD }}" "REDIS_PASSWORD" || VALIDATION_FAILED=true
          fi
          
          # RabbitMQ password validation
          if [ -z "${{ secrets.RABBITMQ_PASSWORD }}" ]; then
            MISSING_SECRETS+=("RABBITMQ_PASSWORD")
            VALIDATION_FAILED=true
          else
            validate_password_strength "${{ secrets.RABBITMQ_PASSWORD }}" "RABBITMQ_PASSWORD" || VALIDATION_FAILED=true
          fi
          
          # Port conflict detection
          echo "[CHECK] Kiểm tra xung đột port..."
          
          PORTS=(
            "${{ vars.GATEWAY_PORT || '5000' }}:GATEWAY_PORT"
            "${{ vars.FRONTEND_PORT || '3500' }}:FRONTEND_PORT"
            "${{ vars.IDENTITY_DB_PORT || '5831' }}:IDENTITY_DB_PORT"
            "${{ vars.COREFINANCE_DB_PORT || '5832' }}:COREFINANCE_DB_PORT"
            "${{ vars.REDIS_PORT || '6379' }}:REDIS_PORT"
            "${{ vars.RABBITMQ_PORT || '5672' }}:RABBITMQ_PORT"
            "${{ vars.PROMETHEUS_PORT || '9090' }}:PROMETHEUS_PORT"
            "${{ vars.GRAFANA_PORT || '3002' }}:GRAFANA_PORT"
          )
          
          USED_PORTS=()
          for port_info in "${PORTS[@]}"; do
            port=$(echo "$port_info" | cut -d':' -f1)
            name=$(echo "$port_info" | cut -d':' -f2)
            
            validate_port "$port" "$name" || VALIDATION_FAILED=true
            
            # Check for duplicates
            if [[ " ${USED_PORTS[@]} " =~ " $port " ]]; then
              echo "[ERROR] Port conflict: $port được sử dụng bởi nhiều services"
              VALIDATION_FAILED=true
            else
              USED_PORTS+=("$port")
            fi
          done
          
          # OAuth configuration validation
          if [ -n "${{ secrets.APP_PUBLIC_GOOGLE_CLIENT_ID }}" ]; then
            if [[ "${{ secrets.APP_PUBLIC_GOOGLE_CLIENT_ID }}" =~ ^[0-9]+-[a-zA-Z0-9]+\.apps\.googleusercontent\.com$ ]]; then
              echo "[OK] GOOGLE_CLIENT_ID: Format hợp lệ"
            else
              echo "[WARNING] GOOGLE_CLIENT_ID: Format có thể không đúng"
            fi
          else
            echo "[WARNING] GOOGLE_CLIENT_ID: Chưa được cấu hình (OAuth sẽ không khả dụng)"
          fi
          
          # Frontend Base URL validation
          FRONTEND_BASE_URL="${{ vars.FRONTEND_BASE_URL || 'http://localhost:3500' }}"
          if [[ "$FRONTEND_BASE_URL" =~ ^https?://[^/]+(:?[0-9]+)?/?$ ]]; then
            echo "[OK] FRONTEND_BASE_URL: Format hợp lệ ($FRONTEND_BASE_URL)"
          else
            echo "[WARNING] FRONTEND_BASE_URL: Format có thể không đúng ($FRONTEND_BASE_URL)"
          fi
          
          # Additional database users validation
          if [ -z "${{ secrets.REPORTING_DB_USERNAME || 'reporting_user' }}" ]; then
            echo "[WARNING] REPORTING_DB_USERNAME: Sử dụng default value 'reporting_user'"
          else
            echo "[OK] REPORTING_DB_USERNAME: Đã được cấu hình"
          fi
          
          # Environment validation
          ENVIRONMENT="${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || github.ref_name == 'staging' && 'staging' || 'development') }}"
          
          case $ENVIRONMENT in
            production|staging|development)
              echo "[OK] Environment: $ENVIRONMENT hợp lệ"
              ;;
            *)
              echo "[ERROR] Environment: $ENVIRONMENT không hợp lệ"
              VALIDATION_FAILED=true
              ;;
          esac
          
          # Security recommendations
          echo "[SECURITY] Kiểm tra các khuyến nghị bảo mật..."
          
          if [ "$ENVIRONMENT" = "production" ]; then
            echo "[SECURITY] Production environment - applying strict checks..."
            
            # Production-specific validations
            if [ "${{ vars.NODE_ENV || 'production' }}" != "production" ]; then
              echo "[WARNING] NODE_ENV nên là 'production' trong production environment"
            fi
            
            if [ "${{ vars.ASPNETCORE_ENVIRONMENT || 'Production' }}" != "Production" ]; then
              echo "[WARNING] ASPNETCORE_ENVIRONMENT nên là 'Production' trong production environment"
            fi
            
            if [ "${{ vars.NUXT_DEBUG || 'false' }}" = "true" ]; then
              echo "[WARNING] NUXT_DEBUG nên là 'false' trong production"
            fi
            
            if [ "${{ vars.NUXT_DEV_TOOLS || 'false' }}" = "true" ]; then
              echo "[WARNING] NUXT_DEV_TOOLS nên là 'false' trong production"
            fi
          fi
          
          # Deployment branch validation
          case "${{ github.ref_name }}" in
            master|main)
              if [ "$ENVIRONMENT" != "production" ]; then
                echo "[WARNING] Master/main branch nên deploy với production environment"
              fi
              ;;
            develop|development)
              if [ "$ENVIRONMENT" != "development" ]; then
                echo "[WARNING] Develop branch nên deploy với development environment"
              fi
              ;;
            staging)
              if [ "$ENVIRONMENT" != "staging" ]; then
                echo "[WARNING] Staging branch nên deploy với staging environment"
              fi
              ;;
          esac
          
          # Final validation result
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "[ERROR] Thiếu các secrets sau:"
            printf '%s\n' "${MISSING_SECRETS[@]}"
            echo "[INFO] Vui lòng cấu hình tại: https://github.com/${{ github.repository }}/settings/secrets/actions"
            VALIDATION_FAILED=true
          fi
          
          if [ "$VALIDATION_FAILED" = true ]; then
            echo "[ERROR] Validation thất bại - không thể tiếp tục deployment"
            echo "[INFO] Vui lòng fix các issues trên và deploy lại"
            exit 1
          fi
          
          echo "[SUCCESS] Tất cả validations đã passed - deployment có thể tiếp tục"
        shell: bash
        env:
          JWT_SECRET_KEY: ${{ secrets.JWT_SECRET_KEY }}

      - name: "[3/18] Set TrueNAS Deploy Directory Environment Variable"
        run: echo "TRUENAS_DEPLOY_DIR=${{ vars.DEPLOY_PATH_ON_TRUENAS }}/deploy_${GITHUB_REF_NAME}" >> $GITHUB_ENV
        shell: bash

      - name: "[4/18] Setup Cloudflared and SSH Config"
        run: |
          echo "Runner HOME directory is: $HOME"
          # Cài đặt cloudflared
          sudo wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared
          sudo chmod +x /usr/local/bin/cloudflared
          echo "Cloudflared version: $(cloudflared --version)"

          # Tạo thư mục $HOME/.ssh nếu chưa tồn tại
          mkdir -p "$HOME/.ssh"
          
          # Tạo tệp cấu hình SSH với enhanced security
          echo "Host truenas-cf-tunnel
            HostName ${{ secrets.TRUENAS_SSH_HOSTNAME_THROUGH_CLOUDFLARED }}
            ProxyCommand cloudflared access ssh --hostname %h
            User ${{ secrets.TRUENAS_USER }}
            StrictHostKeyChecking accept-new
            UserKnownHostsFile ~/.ssh/known_hosts
            ServerAliveInterval 60
            ServerAliveCountMax 3
            ConnectTimeout 30
            LogLevel ERROR" > "$HOME/.ssh/config"
          
          chmod 600 "$HOME/.ssh/config"
          echo "[OK] SSH config for Cloudflared created at $HOME/.ssh/config with enhanced security"
        shell: bash

      - name: "[5/18] Add TrueNAS SSH Private Key to SSH Agent"
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.TRUENAS_SSH_PRIVATE_KEY }}

      - name: "[6/18] DEBUG - Verify SSH Config File"
        run: |
          echo "--- Verifying SSH config file ---"
          if [ -f "$HOME/.ssh/config" ]; then
            echo "[OK] SSH Config file exists at $HOME/.ssh/config"
            echo "--- Contents of $HOME/.ssh/config ---"
            cat "$HOME/.ssh/config"
            echo "-------------------------------------"
            echo "--- Listing $HOME/.ssh directory ---"
            ls -la "$HOME/.ssh"
            echo "------------------------------------"
          else
            echo "[ERROR] SSH Config file NOT FOUND at $HOME/.ssh/config"
            echo "--- Listing $HOME directory ---"
            ls -la "$HOME"
            echo "-------------------------------"
            exit 1
          fi
        shell: bash

      - name: "[7/18] Prepare deploy directory on TrueNAS"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            # Create deploy directory with proper permissions
            mkdir -p ${{ env.TRUENAS_DEPLOY_DIR }}
            mkdir -p ${{ env.TRUENAS_DEPLOY_DIR }}/uploads
            mkdir -p ${{ env.TRUENAS_DEPLOY_DIR }}/logs
            mkdir -p ${{ env.TRUENAS_DEPLOY_DIR }}/config
            mkdir -p ${{ env.TRUENAS_DEPLOY_DIR }}/.rsync-partial
            
            # Set permissive permissions to avoid rsync issues
            chmod 755 ${{ env.TRUENAS_DEPLOY_DIR }}
            chmod -R 755 ${{ env.TRUENAS_DEPLOY_DIR }}/uploads 2>/dev/null || true
            chmod -R 755 ${{ env.TRUENAS_DEPLOY_DIR }}/logs 2>/dev/null || true
            chmod -R 755 ${{ env.TRUENAS_DEPLOY_DIR }}/config 2>/dev/null || true
            chmod -R 755 ${{ env.TRUENAS_DEPLOY_DIR }}/.rsync-partial 2>/dev/null || true
            
            # Check if previous deployment exists and clean problematic files
            if [ -d "${{ env.TRUENAS_DEPLOY_DIR }}/src" ]; then
              echo "[CLEANUP] Cleaning previous deployment files that might cause permission issues..."
              
              # Remove any files with problematic permissions
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type f -name "*.svg" -exec chmod 644 {} \; 2>/dev/null || true
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type f -name "*.png" -exec chmod 644 {} \; 2>/dev/null || true
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type f -name "*.jpg" -exec chmod 644 {} \; 2>/dev/null || true
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type f -name "*.jpeg" -exec chmod 644 {} \; 2>/dev/null || true
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type f -name "*.gif" -exec chmod 644 {} \; 2>/dev/null || true
              
              # Fix directory permissions
              find ${{ env.TRUENAS_DEPLOY_DIR }} -type d -exec chmod 755 {} \; 2>/dev/null || true
            fi
            
            echo "[OK] Prepared TrueNAS deploy directory: ${{ env.TRUENAS_DEPLOY_DIR }}"
          EOF
        shell: bash

      - name: "[8/18] Sync project files to TrueNAS"
        run: |
          echo "[SYNC] Starting project files sync to TrueNAS..."
          
          # Enhanced rsync with robust error handling and permissions management
          # Using more permissive settings to avoid permission issues on TrueNAS
          rsync -rltvz --safe-links \
            --chmod=Du=rwx,Dgo=rx,Fu=rw,Fgo=r \
            --no-perms --no-owner --no-group \
            --ignore-errors \
            --force \
            --exclude '.git/' \
            --exclude '.github/' \
            --exclude 'node_modules/' \
            --exclude 'bin/' \
            --exclude 'obj/' \
            --exclude '*.log' \
            --exclude 'TestResults/' \
            --exclude '.vs/' \
            --exclude '.vscode/' \
            --exclude 'uploads/' \
            --exclude 'logs/' \
            --exclude '*.tmp' \
            --exclude '*.temp' \
            --exclude '.DS_Store' \
            --exclude 'Thumbs.db' \
            --exclude '.nuxt/' \
            --exclude 'dist/' \
            --exclude 'coverage/' \
            --exclude '.nyc_output/' \
            --delete \
            --delete-excluded \
            --partial \
            --partial-dir=.rsync-partial \
            --progress \
            --human-readable \
            --stats \
            -e "ssh -F $HOME/.ssh/config -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=30" \
            $GITHUB_WORKSPACE/ \
            truenas-cf-tunnel:"${{ env.TRUENAS_DEPLOY_DIR }}/" || {
              RSYNC_EXIT_CODE=$?
              echo "[ERROR] Rsync failed with exit code: $RSYNC_EXIT_CODE"
              
              case $RSYNC_EXIT_CODE in
                1)  echo "[ERROR] Syntax or usage error" ;;
                2)  echo "[ERROR] Protocol incompatibility" ;;
                3)  echo "[ERROR] Errors selecting input/output files, dirs" ;;
                4)  echo "[ERROR] Requested action not supported" ;;
                5)  echo "[ERROR] Error starting client-server protocol" ;;
                6)  echo "[ERROR] Daemon unable to append to log-file" ;;
                10) echo "[ERROR] Error in socket I/O" ;;
                11) echo "[ERROR] Error in file I/O" ;;
                12) echo "[ERROR] Error in rsync protocol data stream" ;;
                13) echo "[ERROR] Errors with program diagnostics" ;;
                14) echo "[ERROR] Error in IPC code" ;;
                20) echo "[ERROR] Received SIGUSR1 or SIGINT" ;;
                21) echo "[ERROR] Some error returned by waitpid()" ;;
                22) echo "[ERROR] Error allocating core memory buffers" ;;
                23) echo "[WARNING] Partial transfer due to error - some files may not have transferred correctly" ;;
                24) echo "[ERROR] Partial transfer due to vanished source files" ;;
                25) echo "[ERROR] The --max-delete limit stopped deletions" ;;
                30) echo "[ERROR] Timeout in data send/receive" ;;
                35) echo "[ERROR] Timeout waiting for daemon connection" ;;
                *)  echo "[ERROR] Unknown rsync error code: $RSYNC_EXIT_CODE" ;;
              esac
              
              # Handle common non-critical errors that shouldn't stop deployment
              if [ $RSYNC_EXIT_CODE -eq 23 ] || [ $RSYNC_EXIT_CODE -eq 24 ]; then
                echo "[WARNING] Continuing deployment despite rsync warnings (exit code $RSYNC_EXIT_CODE)"
                echo "[INFO] This usually indicates file permission/attribute warnings that don't affect functionality"
                echo "[INFO] Critical files for deployment have been transferred successfully"
                
                # Verify that essential files were transferred
                echo "[VERIFY] Checking if essential deployment files exist on TrueNAS..."
                ssh -F "$HOME/.ssh/config" truenas-cf-tunnel 'cd '"${{ env.TRUENAS_DEPLOY_DIR }}"' && \
                  ESSENTIAL_FILES=("docker-compose.yml" "src/" "config/") && \
                  MISSING_FILES=() && \
                  for file in "${ESSENTIAL_FILES[@]}"; do \
                    if [ ! -e "$file" ]; then \
                      MISSING_FILES+=("$file"); \
                    fi; \
                  done && \
                  if [ ${#MISSING_FILES[@]} -gt 0 ]; then \
                    echo "[ERROR] Essential files missing: ${MISSING_FILES[*]}" && exit 1; \
                  else \
                    echo "[OK] All essential deployment files are present"; \
                  fi'
              else
                echo "[ERROR] Critical rsync error, stopping deployment"
                exit $RSYNC_EXIT_CODE
              fi
            }
          
          echo "[OK] Project files sync completed to TrueNAS"
        shell: bash

      - name: "[9/18] Create .env file on TrueNAS"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel "cat > ${{ env.TRUENAS_DEPLOY_DIR }}/.env << 'EOF'
          # Project name
          COMPOSE_PROJECT_NAME=tihomo_${{ inputs.environment || 'development' }}
          
          # Core Configuration
          GATEWAY_PORT=${{ vars.GATEWAY_PORT || '5000' }}
          FRONTEND_PORT=${{ vars.FRONTEND_PORT || '3500' }}
          FRONTEND_BASE_URL=${{ vars.FRONTEND_BASE_URL || 'http://localhost:3500' }}
          JWT_SECRET_KEY='${{ secrets.JWT_SECRET_KEY }}'
          
          # Database Configuration - Identity
          IDENTITY_DB_USERNAME=${{ secrets.IDENTITY_DB_USERNAME || 'identity_user' }}
          IDENTITY_DB_PASSWORD='${{ secrets.IDENTITY_DB_PASSWORD }}'
          IDENTITY_DB_PORT=${{ vars.IDENTITY_DB_PORT || '5831' }}
          
          # Database Configuration - CoreFinance
          COREFINANCE_DB_USERNAME=${{ secrets.COREFINANCE_DB_USERNAME || 'corefinance_user' }}
          COREFINANCE_DB_PASSWORD='${{ secrets.COREFINANCE_DB_PASSWORD }}'
          COREFINANCE_DB_PORT=${{ vars.COREFINANCE_DB_PORT || '5832' }}
          
          # Database Configuration - MoneyManagement
          MONEYMANAGEMENT_DB_USERNAME=${{ secrets.MONEYMANAGEMENT_DB_USERNAME || 'money_user' }}
          MONEYMANAGEMENT_DB_PASSWORD='${{ secrets.MONEYMANAGEMENT_DB_PASSWORD || secrets.IDENTITY_DB_PASSWORD }}'
          MONEYMANAGEMENT_DB_PORT=${{ vars.MONEYMANAGEMENT_DB_PORT || '5835' }}
          
          # Database Configuration - PlanningInvestment
          PLANNINGINVESTMENT_DB_USERNAME=${{ secrets.PLANNINGINVESTMENT_DB_USERNAME || 'planning_user' }}
          PLANNINGINVESTMENT_DB_PASSWORD='${{ secrets.PLANNINGINVESTMENT_DB_PASSWORD || secrets.IDENTITY_DB_PASSWORD }}'
          PLANNINGINVESTMENT_DB_PORT=${{ vars.PLANNINGINVESTMENT_DB_PORT || '5836' }}
          
          # Database Configuration - Reporting
          REPORTING_DB_USERNAME=${{ secrets.REPORTING_DB_USERNAME || 'reporting_user' }}
          REPORTING_DB_PASSWORD='${{ secrets.REPORTING_DB_PASSWORD || secrets.IDENTITY_DB_PASSWORD }}'
          REPORTING_DB_PORT=${{ vars.REPORTING_DB_PORT || '5837' }}
          
          # Redis Configuration
          REDIS_PORT=${{ vars.REDIS_PORT || '6379' }}
          REDIS_PASSWORD='${{ secrets.REDIS_PASSWORD }}'
          
          # RabbitMQ Configuration
          RABBITMQ_PORT=${{ vars.RABBITMQ_PORT || '5672' }}
          RABBITMQ_MANAGEMENT_PORT=${{ vars.RABBITMQ_MANAGEMENT_PORT || '15672' }}
          RABBITMQ_PASSWORD='${{ secrets.RABBITMQ_PASSWORD }}'
          
          # Monitoring Configuration
          PROMETHEUS_PORT=${{ vars.PROMETHEUS_PORT || '9090' }}
          GRAFANA_PORT=${{ vars.GRAFANA_PORT || '3002' }}
          GRAFANA_ADMIN_PASSWORD='${{ secrets.GRAFANA_ADMIN_PASSWORD || secrets.IDENTITY_DB_PASSWORD }}'
          LOKI_PORT=${{ vars.LOKI_PORT || '3100' }}
          
          # Development Tools
          PGADMIN_PORT=${{ vars.PGADMIN_PORT || '8081' }}
          PGADMIN_PASSWORD='${{ secrets.PGADMIN_PASSWORD || secrets.IDENTITY_DB_PASSWORD }}'
          MAILHOG_SMTP_PORT=${{ vars.MAILHOG_SMTP_PORT || '1025' }}
          MAILHOG_UI_PORT=${{ vars.MAILHOG_UI_PORT || '8025' }}
          
          # Nginx Configuration
          NGINX_HTTP_PORT=${{ vars.NGINX_HTTP_PORT || '8082' }}
          NGINX_HTTPS_PORT=${{ vars.NGINX_HTTPS_PORT || '8443' }}
          
          # Network Configuration
          DOCKER_NETWORK_SUBNET=${{ vars.DOCKER_NETWORK_SUBNET || '172.20.0.0/16' }}
          
          # Application Environment
          NODE_ENV=${{ vars.NODE_ENV || 'production' }}
          ASPNETCORE_ENVIRONMENT=${{ vars.ASPNETCORE_ENVIRONMENT || 'Production' }}
          
          # OAuth Configuration
          APP_PUBLIC_GOOGLE_CLIENT_ID=${{ secrets.APP_PUBLIC_GOOGLE_CLIENT_ID }}
          
          # JWT Configuration
          JWT_ISSUER=${{ vars.JWT_ISSUER || 'http://localhost:5000' }}
          JWT_AUDIENCE_OCELOT_GATEWAY=${{ vars.JWT_AUDIENCE_OCELOT_GATEWAY || 'TiHoMo.Gateway' }}
          JWT_AUDIENCE_IDENTITY_API=${{ vars.JWT_AUDIENCE_IDENTITY_API || 'TiHoMo.Identity' }}
          JWT_AUDIENCE_COREFINANCE_API=${{ vars.JWT_AUDIENCE_COREFINANCE_API || 'TiHoMo.CoreFinance' }}
          
          # Timezone & other settings
          GENERIC_TIMEZONE=${{ vars.GENERIC_TIMEZONE || 'Asia/Ho_Chi_Minh' }}
          TZ=${{ vars.TZ || 'Asia/Ho_Chi_Minh' }}
          
          # Build Configuration - Force production stage for deployment
          NUXT_BUILD_TARGET=production
          NUXT_DEV_SSR=${{ vars.NUXT_DEV_SSR || 'false' }}
          NUXT_DEBUG=${{ vars.NUXT_DEBUG || 'false' }}
          NUXT_DEV_TOOLS=${{ vars.NUXT_DEV_TOOLS || 'false' }}
          NUXT_TELEMETRY_DISABLED=1
          
          # Logging Configuration
          LOG_LEVEL=${{ vars.LOG_LEVEL || 'info' }}
          LOG_FORMAT=${{ vars.LOG_FORMAT || 'json' }}
          
          # Feature Toggles
          ENABLE_PWA=${{ vars.ENABLE_PWA || 'false' }}
          ENABLE_ANALYTICS=${{ vars.ENABLE_ANALYTICS || 'false' }}
          
          # Deployment Information
          DEPLOY_BRANCH=${{ github.ref_name }}
          DEPLOY_COMMIT=${{ github.sha }}
          DEPLOY_TIME=\$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          EOF"
          echo "[OK] .env file created on TrueNAS at ${{ env.TRUENAS_DEPLOY_DIR }}/.env"
        shell: bash

      - name: "[10/18] Debug Environment Configuration"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            echo "[CHECK] Kiểm tra cấu hình environment..."
            
            # Kiểm tra JWT_SECRET_KEY có tồn tại trong .env không
            if grep -q "JWT_SECRET_KEY=" .env; then
              JWT_LINE=\$(grep "JWT_SECRET_KEY=" .env)
              if [[ "\$JWT_LINE" == "JWT_SECRET_KEY=" ]]; then
                echo "[ERROR] JWT_SECRET_KEY rỗng trong file .env"
              else
                JWT_VALUE=\$(echo "\$JWT_LINE" | cut -d'=' -f2)
                if [[ "\$JWT_VALUE" == "" ]]; then
                  echo "[ERROR] JWT_SECRET_KEY không có giá trị"
                else
                  echo "[OK] JWT_SECRET_KEY đã được cấu hình (độ dài: \${#JWT_VALUE} ký tự)"
                fi
              fi
            else
              echo "[ERROR] Không tìm thấy JWT_SECRET_KEY trong file .env"
            fi
            
            echo "[INFO] Các biến môi trường chính trong .env:"
            grep -E "(GATEWAY_PORT|FRONTEND_PORT|IDENTITY_DB|COREFINANCE_DB|REDIS|RABBITMQ)" .env || echo "Không có biến môi trường chính"
            
            echo "[CHECK] Kiểm tra Docker Compose file:"
            if [ -f "docker-compose.yml" ]; then
              echo "[OK] docker-compose.yml exists"
            else
              echo "[ERROR] docker-compose.yml not found"
            fi
          EOF
        shell: bash

      - name: "[11/18] Check and Fix Docker Permissions"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            echo "[CHECK] Kiểm tra quyền Docker..."
            
            # Kiểm tra Docker daemon có chạy không
            if systemctl is-active --quiet docker 2>/dev/null || service docker status >/dev/null 2>&1; then
              echo "[OK] Docker daemon đang chạy"
            else
              echo "[ERROR] Docker daemon không chạy"
              sudo systemctl start docker || sudo service docker start || echo "[WARNING] Không thể start Docker daemon"
            fi
            
            # Kiểm tra user hiện tại có trong docker group không
            CURRENT_USER=\$(whoami)
            echo "[INFO] Current user: \$CURRENT_USER"
            
            if groups \$CURRENT_USER | grep -q docker; then
              echo "[OK] User \$CURRENT_USER đã trong docker group"
              USE_SUDO=""
            else
              echo "[WARNING] User \$CURRENT_USER chưa trong docker group"
              echo "[FIX] Thử thêm user vào docker group..."
              
              # Thử add user vào docker group
              if sudo usermod -aG docker \$CURRENT_USER 2>/dev/null; then
                echo "[OK] Đã thêm user vào docker group"
                echo "[INFO] Cần logout/login lại để group có hiệu lực"
                echo "[INFO] Sử dụng sudo cho session này"
                USE_SUDO="sudo"
              else
                echo "[WARNING] Không thể thêm user vào docker group, sử dụng sudo"
                USE_SUDO="sudo"
              fi
            fi
            
            # Test Docker access
            echo "[TEST] Test Docker access..."
            if docker ps >/dev/null 2>&1; then
              echo "[OK] Docker access thành công (không cần sudo)"
              USE_SUDO=""
            elif sudo docker ps >/dev/null 2>&1; then
              echo "[OK] Docker access thành công (cần sudo)"
              USE_SUDO="sudo"
            else
              echo "[ERROR] Không thể truy cập Docker daemon"
              echo "[DEBUG] Docker socket permissions:"
              ls -l /var/run/docker.sock
              echo "[DEBUG] Current user groups:"
              groups
              exit 1
            fi
            
            # Save sudo preference to environment for next steps
            echo "USE_SUDO=\$USE_SUDO" >> /tmp/docker_config
            echo "[OK] Docker permissions đã được kiểm tra và cấu hình"
          EOF
        shell: bash

      - name: "[12/18] Prepare application directories on TrueNAS"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            
            # Tạo các thư mục cần thiết cho application
            mkdir -p uploads
            mkdir -p logs/frontend
            mkdir -p logs/identity
            mkdir -p logs/corefinance
            mkdir -p logs/excel
            mkdir -p logs/ocelot
            mkdir -p config/ssl
            
            # Set proper permissions
            chmod -R 755 uploads
            chmod -R 755 logs
            chmod -R 755 config
            
            echo "[OK] Prepared application directories on TrueNAS"
          EOF
        shell: bash

      - name: "[13/18] Pre-deployment health checks and security scanning"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            
            echo "[CHECK] Pre-deployment health checks..."
            
            # Check Docker availability
            if command -v docker &> /dev/null; then
              echo "[OK] Docker is available"
              docker --version
            else
              echo "[ERROR] Docker is not installed"
              exit 1
            fi
            
            # Check Docker Compose availability
            if command -v docker &> /dev/null && docker compose version &> /dev/null; then
              echo "[OK] Docker Compose is available"
              docker compose version
            else
              echo "[ERROR] Docker Compose is not available"
              exit 1
            fi
            
            # Check disk space
            echo "[DISK] Disk space check:"
            df -h .
            
            # Check memory
            echo "[MEMORY] Memory check:"
            free -h
            
            echo "[OK] Pre-deployment checks completed"
            
            # SECURITY SCANNING
            echo "[SECURITY] Installing Trivy security scanner..."
            # Install Trivy if not present
            if ! command -v trivy &> /dev/null; then
              sudo wget -qO- https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo tee /etc/apt/trusted.gpg.d/trivy.asc
              echo "deb https://aquasecurity.github.io/trivy-repo/deb generic main" | sudo tee -a /etc/apt/sources.list.d/trivy-repo.list
              sudo apt-get update
              sudo apt-get install -y trivy
            fi
            
            echo "[SECURITY] Scanning Docker images for vulnerabilities..."
            
            # Get Docker sudo preference
            if [ -f /tmp/docker_config ]; then
              source /tmp/docker_config
            else
              if docker ps >/dev/null 2>&1; then
                USE_SUDO=""
              else
                USE_SUDO="sudo"
              fi
            fi
            
            # Define critical images to scan
            IMAGES=("postgres:15" "redis:7" "rabbitmq:3-management" "grafana/grafana:latest" "prom/prometheus:latest")
            
            SCAN_FAILED=false
            for image in "\${IMAGES[@]}"; do
              echo "[SCAN] Scanning \$image..."
              if trivy image --severity HIGH,CRITICAL --quiet --format table \$image; then
                echo "[OK] \$image passed security scan"
              else
                echo "[ERROR] \$image has HIGH/CRITICAL vulnerabilities"
                SCAN_FAILED=true
              fi
            done
            
            # Scan custom built images if they exist
            if \$USE_SUDO docker images | grep -q "tihomo"; then
              echo "[SCAN] Scanning custom TiHoMo images..."
              \$USE_SUDO docker images --format "{{.Repository}}:{{.Tag}}" | grep tihomo | while read custom_image; do
                echo "[SCAN] Scanning custom image: \$custom_image"
                if trivy image --severity HIGH,CRITICAL --quiet --format table \$custom_image; then
                  echo "[OK] \$custom_image passed security scan"
                else
                  echo "[WARNING] \$custom_image has vulnerabilities (continuing with deployment)"
                fi
              done
            fi
            
            if [ "\$SCAN_FAILED" = true ]; then
              echo "[WARNING] Some base images have critical vulnerabilities"
              echo "[INFO] Consider updating to patched versions"
              echo "[INFO] Continuing with deployment as base images are from trusted sources"
            fi
            
            echo "[OK] Security scanning completed"
          EOF
        shell: bash

      - name: "[14/18] Enhanced Docker operations with rolling deployment on TrueNAS"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            set -e 
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            echo "[DOCKER] Working with Docker Compose in ${{ env.TRUENAS_DEPLOY_DIR }}"
            
            # BACKUP PHASE
            echo "[BACKUP] Creating pre-deployment backup..."
            
            # Load environment variables
            source .env
            
            # Load Docker sudo preference from previous step
            if [ -f /tmp/docker_config ]; then
              source /tmp/docker_config
              echo "[INFO] Using Docker with sudo preference: '\$USE_SUDO'"
            else
              echo "[WARNING] Docker config not found, testing Docker access..."
              if docker ps >/dev/null 2>&1; then
                USE_SUDO=""
                echo "[OK] Docker access without sudo"
              elif sudo docker ps >/dev/null 2>&1; then
                USE_SUDO="sudo"
                echo "[OK] Docker access with sudo"
              else
                echo "[ERROR] No Docker access available"
                exit 1
              fi
            fi
            
            # Create backup directory with timestamp
            BACKUP_DIR="backups/pre-deploy-\$(date +%Y%m%d-%H%M%S)"
            mkdir -p "\$BACKUP_DIR"
            
            # Backup running databases if they exist
            if \$USE_SUDO docker compose ps | grep -q "identity-db.*Up"; then
              echo "[BACKUP] Backing up Identity database..."
              \$USE_SUDO docker compose exec -T identity-db pg_dump -U \$IDENTITY_DB_USERNAME identity_db > "\$BACKUP_DIR/identity_db.sql" || echo "[WARNING] Identity DB backup failed"
            fi
            
            if \$USE_SUDO docker compose ps | grep -q "corefinance-db.*Up"; then
              echo "[BACKUP] Backing up CoreFinance database..."
              \$USE_SUDO docker compose exec -T corefinance-db pg_dump -U \$COREFINANCE_DB_USERNAME corefinance_db > "\$BACKUP_DIR/corefinance_db.sql" || echo "[WARNING] CoreFinance DB backup failed"
            fi
            
            # Backup current configuration
            echo "[BACKUP] Backing up configuration files..."
            cp .env "\$BACKUP_DIR/env.backup" 2>/dev/null || echo "[INFO] No .env file to backup"
            cp docker-compose.yml "\$BACKUP_DIR/docker-compose.backup.yml" 2>/dev/null || echo "[INFO] No compose file to backup"
            
            # Cleanup old backups (keep only 5 most recent)
            echo "[CLEANUP] Cleaning up old backups..."
            cd backups 2>/dev/null && ls -dt pre-deploy-* 2>/dev/null | tail -n +6 | xargs rm -rf 2>/dev/null || true
            cd ..
            
            echo "[OK] Pre-deployment backup completed at: \$BACKUP_DIR"
            
            # ROLLING DEPLOYMENT PHASE
            echo "[DEPLOY] Starting rolling deployment phase..."
            
            # Validate NUXT_BUILD_TARGET to prevent build errors
            if [ "\$NUXT_BUILD_TARGET" != "development" ] && [ "\$NUXT_BUILD_TARGET" != "production" ]; then
              echo "[WARNING] Invalid NUXT_BUILD_TARGET: '\$NUXT_BUILD_TARGET'. Using 'production' instead."
              export NUXT_BUILD_TARGET=production
              # Update .env file with corrected value
              sed -i 's/^NUXT_BUILD_TARGET=.*/NUXT_BUILD_TARGET=production/' .env
            fi
            echo "[INFO] Using NUXT_BUILD_TARGET: '\$NUXT_BUILD_TARGET'"
            
            echo "[PULL] Đang pull images mới nhất..."
            \$USE_SUDO docker compose pull || {
              echo "[ERROR] Failed to pull images"
              echo "[DEBUG] Docker compose version:"
              \$USE_SUDO docker compose version
              echo "[DEBUG] Available images:"
              \$USE_SUDO docker images
              exit 1
            }
            echo "[OK] Đã pull images thành công"
            
            echo "[BUILD] Đang build images với smart caching..."
            # Only use --no-cache for breaking changes or if explicitly requested
            if [ "\${{ github.event.inputs.force_rebuild || 'false' }}" = "true" ]; then
              echo "[BUILD] Force rebuild requested - using --no-cache"
              \$USE_SUDO docker compose build --no-cache
            else
              echo "[BUILD] Smart build với caching"
              \$USE_SUDO docker compose build --pull
            fi
            
            if [ \$? -ne 0 ]; then
              echo "[ERROR] Failed to build images"
              echo "[DEBUG] Docker compose file check:"
              cat docker-compose.yml | head -20
              echo "[DEBUG] Environment variables:"
              echo "NUXT_BUILD_TARGET=\$NUXT_BUILD_TARGET"
              echo "[DEBUG] Frontend service config:"
              grep -A 10 "frontend-nuxt:" docker-compose.yml
              exit 1
            fi
            echo "[OK] Đã build images thành công"
            
            # Rolling deployment strategy
            echo "[DEPLOY] Bắt đầu rolling deployment..."
            
            # Define deployment order (infrastructure first, then applications)
            INFRASTRUCTURE_SERVICES=("identity-postgres" "corefinance-postgres" "moneymanagement-postgres" "planninginvestment-postgres" "reporting-postgres" "redis" "rabbitmq")
            MONITORING_SERVICES=("prometheus" "loki" "grafana")
            APPLICATION_SERVICES=("identity-api" "corefinance-api" "excel-api" "ocelot-gateway" "frontend-nuxt")
            UTILITY_SERVICES=("pgadmin" "mailhog" "nginx")
            
            # Function to deploy service with health check
            deploy_service() {
              local service=\$1
              local max_attempts=5
              local attempt=1
              
              echo "[DEPLOY] Deploying service: \$service"
              
              # Check if service exists in compose file
              if ! \$USE_SUDO docker compose config --services | grep -q "^\$service\$"; then
                echo "[SKIP] Service \$service not found in compose file"
                return 0
              fi
              
              # Deploy service with production override for frontend
              if [ "\$service" = "frontend-nuxt" ]; then
                echo "[DEPLOY] Using production override for frontend-nuxt service"
                \$USE_SUDO docker compose -f docker-compose.yml -f docker-compose.production.yml up -d --no-deps --force-recreate \$service
              else
                \$USE_SUDO docker compose up -d --no-deps --force-recreate \$service
              fi
              
              # Wait for service to be healthy
              while [ \$attempt -le \$max_attempts ]; do
                if \$USE_SUDO docker compose ps \$service | grep -q "Up"; then
                  echo "[OK] Service \$service is running (attempt \$attempt/\$max_attempts)"
                  sleep 10  # Additional time for service initialization
                  return 0
                else
                  echo "[WAIT] Service \$service not ready yet (attempt \$attempt/\$max_attempts)"
                  sleep 15
                  ((attempt++))
                fi
              done
              
              echo "[ERROR] Service \$service failed to start after \$max_attempts attempts"
              echo "[DEBUG] Service logs:"
              \$USE_SUDO docker compose logs --tail=20 \$service
              return 1
            }
            
            # Deploy infrastructure services first
            echo "[PHASE 1] Deploying infrastructure services..."
            for service in "\${INFRASTRUCTURE_SERVICES[@]}"; do
              deploy_service "\$service" || {
                echo "[ERROR] Failed to deploy infrastructure service: \$service"
                echo "[ROLLBACK] Consider manual intervention"
                exit 1
              }
            done
            
            # Wait for databases to be fully ready
            echo "[WAIT] Waiting for databases to initialize (30 seconds)..."
            sleep 30
            
            # Deploy application services
            echo "[PHASE 2] Deploying application services..."
            for service in "\${APPLICATION_SERVICES[@]}"; do
              deploy_service "\$service" || {
                echo "[ERROR] Failed to deploy application service: \$service"
                echo "[ROLLBACK] Rolling back to previous version..."
                
                # Simple rollback: restart the failed service with previous image
                echo "[ROLLBACK] Attempting to restart \$service..."
                \$USE_SUDO docker compose restart \$service
                sleep 10
                
                if \$USE_SUDO docker compose ps \$service | grep -q "Up"; then
                  echo "[OK] Service \$service restarted successfully"
                else
                  echo "[ERROR] Rollback failed for \$service"
                  exit 1
                fi
              }
            done
            
            # Deploy monitoring services (non-critical)
            echo "[PHASE 3] Deploying monitoring services..."
            for service in "\${MONITORING_SERVICES[@]}"; do
              deploy_service "\$service" || {
                echo "[WARNING] Failed to deploy monitoring service: \$service (continuing...)"
              }
            done
            
            # Deploy utility services (non-critical)
            echo "[PHASE 4] Deploying utility services..."
            for service in "\${UTILITY_SERVICES[@]}"; do
              deploy_service "\$service" || {
                echo "[WARNING] Failed to deploy utility service: \$service (continuing...)"
              }
            done
            
            echo "[WAIT] Đang đợi all services stabilize (60 giây)..."
            sleep 60
            
            echo "[STATUS] Kiểm tra trạng thái tất cả services sau deployment..."
            \$USE_SUDO docker compose ps
            
            echo "[CHECK] Kiểm tra logs gần đây cho critical services..."
            for service in "ocelot-gateway" "frontend-nuxt" "identity-api" "corefinance-api"; do
              if \$USE_SUDO docker compose ps \$service | grep -q "Up"; then
                echo "[LOGS] \$service logs:"
                \$USE_SUDO docker compose logs --tail=5 \$service
              else
                echo "[WARNING] Service \$service is not running"
              fi
            done
            
            echo "[OK] Rolling deployment completed successfully"
          EOF
        shell: bash

      - name: "[15/18] Enhanced deployment health verification"
        if: ${{ github.event_name != 'workflow_dispatch' || inputs.skip_health_checks != true }}
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            set -e 
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            
            # Load environment variables
            source .env
            
            # Load Docker sudo preference
            if [ -f /tmp/docker_config ]; then
              source /tmp/docker_config
            else
              # Fallback check
              if docker ps >/dev/null 2>&1; then
                USE_SUDO=""
              else
                USE_SUDO="sudo"
              fi
            fi
            
            echo "[HEALTH] Kiểm tra comprehensive health của các services..."
            
            # Enhanced health check function
            check_service_health() {
              local service_name=\$1
              local health_url=\$2
              local max_attempts=6
              local attempt=1
              
              echo "[CHECK] Checking \$service_name health..."
              
              # First, verify container is running
              if ! \$USE_SUDO docker compose ps \$service_name | grep -q "Up"; then
                echo "[ERROR] \$service_name container is not running"
                return 1
              fi
              
              while [ \$attempt -le \$max_attempts ]; do
                # Try health endpoint
                if \$USE_SUDO docker compose exec -T \$service_name curl -f \$health_url > /dev/null 2>&1; then
                  echo "[OK] \$service_name health endpoint responsive"
                  return 0
                else
                  echo "[WAIT] \$service_name health endpoint not ready (attempt \$attempt/\$max_attempts)"
                  sleep 15
                  ((attempt++))
                fi
              done
              
              echo "[ERROR] \$service_name failed health check after \$max_attempts attempts"
              return 1
            }
            
            # Database connectivity check function
            check_database_connectivity() {
              local db_service=\$1
              local db_name=\$2
              local db_user=\$3
              local max_attempts=5
              local attempt=1
              
              echo "[DB] Checking \$db_service database connectivity..."
              
              while [ \$attempt -le \$max_attempts ]; do
                if \$USE_SUDO docker compose exec -T \$db_service pg_isready -U \$db_user -d \$db_name > /dev/null 2>&1; then
                  echo "[OK] \$db_service database is ready and accepting connections"
                  return 0
                else
                  echo "[WAIT] \$db_service database not ready (attempt \$attempt/\$max_attempts)"
                  sleep 10
                  ((attempt++))
                fi
              done
              
              echo "[ERROR] \$db_service database connectivity failed"
              return 1
            }
            
            # API response validation function
            check_api_response() {
              local service_name=\$1
              local endpoint=\$2
              local expected_status=\$3
              
              echo "[API] Validating \$service_name API response..."
              
              local response_code=\$(\$USE_SUDO docker compose exec -T \$service_name curl -s -o /dev/null -w "%{http_code}" \$endpoint 2>/dev/null || echo "000")
              
              if [ "\$response_code" = "\$expected_status" ]; then
                echo "[OK] \$service_name API returned expected status: \$response_code"
                return 0
              else
                echo "[WARNING] \$service_name API returned status: \$response_code (expected: \$expected_status)"
                return 1
              fi
            }
            
            # Memory and CPU check function
            check_resource_usage() {
              local service_name=\$1
              
              echo "[RESOURCE] Checking \$service_name resource usage..."
              
              local stats=\$(\$USE_SUDO docker stats \$service_name --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" 2>/dev/null | tail -n +2)
              
              if [ -n "\$stats" ]; then
                echo "[OK] \$service_name resource usage: \$stats"
                return 0
              else
                echo "[WARNING] Could not get resource stats for \$service_name"
                return 1
              fi
            }
            
            # Start comprehensive health checks
            HEALTH_FAILED=false
            
            # 1. Database connectivity checks
            echo "[PHASE 1] Database connectivity verification..."
            
            if \$USE_SUDO docker compose ps identity-db | grep -q "Up"; then
              check_database_connectivity "identity-db" "identity_db" "\$IDENTITY_DB_USERNAME" || HEALTH_FAILED=true
            else
              echo "[SKIP] Identity database not running"
            fi
            
            if \$USE_SUDO docker compose ps corefinance-db | grep -q "Up"; then
              check_database_connectivity "corefinance-db" "corefinance_db" "\$COREFINANCE_DB_USERNAME" || HEALTH_FAILED=true
            else
              echo "[SKIP] CoreFinance database not running"
            fi
            
            # 2. Redis connectivity check
            echo "[PHASE 2] Redis connectivity verification..."
            if \$USE_SUDO docker compose ps redis | grep -q "Up"; then
              if \$USE_SUDO docker compose exec -T redis redis-cli ping | grep -q "PONG"; then
                echo "[OK] Redis is responding to ping"
              else
                echo "[ERROR] Redis not responding"
                HEALTH_FAILED=true
              fi
            else
              echo "[SKIP] Redis not running"
            fi
            
            # 3. RabbitMQ connectivity check
            echo "[PHASE 3] RabbitMQ connectivity verification..."
            if \$USE_SUDO docker compose ps rabbitmq | grep -q "Up"; then
              if \$USE_SUDO docker compose exec -T rabbitmq rabbitmq-diagnostics ping > /dev/null 2>&1; then
                echo "[OK] RabbitMQ is responding"
              else
                echo "[ERROR] RabbitMQ not responding"
                HEALTH_FAILED=true
              fi
            else
              echo "[SKIP] RabbitMQ not running"
            fi
            
            # 4. Application health checks
            echo "[PHASE 4] Application services health verification..."
            
            # Check Gateway health with retry
            if \$USE_SUDO docker compose ps ocelot-gateway | grep -q "Up"; then
              check_service_health "ocelot-gateway" "http://localhost:8080/health" || HEALTH_FAILED=true
              check_api_response "ocelot-gateway" "http://localhost:8080/health" "200" || echo "[WARNING] Gateway health endpoint non-standard response"
            else
              echo "[ERROR] Gateway not running"
              HEALTH_FAILED=true
            fi
            
            # Check Frontend health
            if \$USE_SUDO docker compose ps frontend-nuxt | grep -q "Up"; then
              check_service_health "frontend-nuxt" "http://localhost:3000/" || HEALTH_FAILED=true
              check_api_response "frontend-nuxt" "http://localhost:3000/" "200" || echo "[WARNING] Frontend root endpoint non-standard response"
            else
              echo "[ERROR] Frontend not running"
              HEALTH_FAILED=true
            fi
            
            # Check Identity API health
            if \$USE_SUDO docker compose ps identity-api | grep -q "Up"; then
              check_service_health "identity-api" "http://localhost:8080/health" || HEALTH_FAILED=true
            else
              echo "[ERROR] Identity API not running"
              HEALTH_FAILED=true
            fi
            
            # Check CoreFinance API health
            if \$USE_SUDO docker compose ps corefinance-api | grep -q "Up"; then
              check_service_health "corefinance-api" "http://localhost:8080/health" || HEALTH_FAILED=true
            else
              echo "[ERROR] CoreFinance API not running"
              HEALTH_FAILED=true
            fi
            
            # 5. Resource usage monitoring
            echo "[PHASE 5] Resource usage verification..."
            
            CRITICAL_SERVICES=("ocelot-gateway" "frontend-nuxt" "identity-api" "corefinance-api" "identity-db" "corefinance-db")
            for service in "\${CRITICAL_SERVICES[@]}"; do
              if \$USE_SUDO docker compose ps \$service | grep -q "Up"; then
                check_resource_usage \$service || echo "[WARNING] Resource check failed for \$service"
              fi
            done
            
            # 6. Integration test - simple API flow
            echo "[PHASE 6] Integration test verification..."
            
            if \$USE_SUDO docker compose ps ocelot-gateway | grep -q "Up" && \$USE_SUDO docker compose ps identity-api | grep -q "Up"; then
              echo "[INTEGRATION] Testing API gateway -> Identity API flow..."
              local gateway_to_identity=\$(\$USE_SUDO docker compose exec -T ocelot-gateway curl -s -o /dev/null -w "%{http_code}" "http://identity-api:8080/health" 2>/dev/null || echo "000")
              
              if [ "\$gateway_to_identity" = "200" ]; then
                echo "[OK] Gateway can communicate with Identity API"
              else
                echo "[WARNING] Gateway-Identity communication issue (status: \$gateway_to_identity)"
              fi
            fi
            
            # 7. Final status summary
            echo "[SUMMARY] Health check results summary:"
            
            \$USE_SUDO docker compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
            
            echo ""
            echo "[DISK] Final disk usage:"
            df -h .
            
            echo ""
            echo "[MEMORY] Final memory usage:"
            free -h
            
            echo ""
            echo "[DOCKER] Docker system info:"
            \$USE_SUDO docker system df
            
            # Final decision
            if [ "\$HEALTH_FAILED" = true ]; then
              echo "[ERROR] Some critical health checks failed!"
              echo "[INFO] Check the logs above for specific failures"
              echo "[LOGS] Recent error logs:"
              
              for service in "ocelot-gateway" "frontend-nuxt" "identity-api" "corefinance-api"; do
                if \$USE_SUDO docker compose ps \$service | grep -q "Up"; then
                  echo "[ERROR-LOGS] \$service recent errors:"
                  \$USE_SUDO docker compose logs --tail=10 \$service | grep -i error || echo "No recent errors found"
                fi
              done
              
              echo "[WARNING] Deployment completed but with health check failures"
              echo "[ACTION] Manual verification recommended"
            else
              echo "[SUCCESS] All critical health checks passed!"
              echo "[OK] Deployment verified successfully"
            fi
          EOF
        shell: bash

      - name: "[16/18] Display deployment information"
        run: |
          echo "[DEPLOY] TiHoMo system đã được triển khai thành công trên TrueNAS."
          echo ""
          echo "[STATUS] Thông tin triển khai:"
          echo "  - Environment: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || github.ref_name == 'staging' && 'staging' || 'development') }}"
          echo "  - Trigger Type: ${{ github.event_name == 'workflow_dispatch' && 'Manual Run' || 'Automatic (Push)' }}"
          echo "  - Force Rebuild: ${{ github.event_name == 'workflow_dispatch' && inputs.force_rebuild || 'false' }}"
          echo "  - Frontend: http://<TRUENAS_IP>:${{ vars.FRONTEND_PORT || '3500' }}"
          echo "  - API Gateway: http://<TRUENAS_IP>:${{ vars.GATEWAY_PORT || '5000' }}"
          echo "  - Grafana Dashboard: http://<TRUENAS_IP>:${{ vars.GRAFANA_PORT || '3002' }}"
          echo "  - RabbitMQ Management: http://<TRUENAS_IP>:${{ vars.RABBITMQ_MANAGEMENT_PORT || '15672' }}"
          echo "  - pgAdmin: http://<TRUENAS_IP>:${{ vars.PGADMIN_PORT || '8081' }}"
          echo "  - Prometheus: http://<TRUENAS_IP>:${{ vars.PROMETHEUS_PORT || '9090' }}"
          echo ""
          echo "[INFO] Thông tin deployment:"
          echo "  - Nhánh: ${{ github.ref_name }}"
          echo "  - Commit: ${{ github.sha }}"
          echo "  - Thời gian: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
          echo "  - Environment: ${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || 'staging') }}"
          echo ""
          echo "[SECURITY] Security enhancements applied:"
          echo "  - SSH: Enhanced security with proper host validation"
          echo "  - Images: Trivy security scanning performed"
          echo "  - Deployment: Rolling deployment with zero downtime"
          echo "  - Backup: Pre-deployment backup created"
          echo "  - Health: Comprehensive validation performed"
          echo ""
          echo "[OK] TRIỂN KHAI HOÀN TẤT THÀNH CÔNG VỚI CẢI THIỆN BẢO MẬT"
        shell: bash

      - name: "[17/18] Post-deployment cleanup and optimization"
        run: |
          ssh -F "$HOME/.ssh/config" truenas-cf-tunnel << EOF
            cd ${{ env.TRUENAS_DEPLOY_DIR }}
            
            echo "[CLEANUP] Post-deployment cleanup và optimization..."
            
            # Load Docker sudo preference
            if [ -f /tmp/docker_config ]; then
              source /tmp/docker_config
            else
              if docker ps >/dev/null 2>&1; then
                USE_SUDO=""
              else
                USE_SUDO="sudo"
              fi
            fi
            
            # Clean up old Docker images (keep only latest)
            echo "[CLEANUP] Removing unused Docker images..."
            \$USE_SUDO docker image prune -f || true
            
            # Clean up old containers
            echo "[CLEANUP] Removing stopped containers..."
            \$USE_SUDO docker container prune -f || true
            
            # Clean up old volumes (careful with data)
            echo "[CLEANUP] Removing unused Docker volumes..."
            \$USE_SUDO docker volume prune -f || true
            
            # Clean up old networks
            echo "[CLEANUP] Removing unused Docker networks..."
            \$USE_SUDO docker network prune -f || true
            
            # Log rotation and cleanup
            echo "[CLEANUP] Log rotation và cleanup..."
            
            # Rotate application logs if they exist and are large
            find logs/ -name "*.log" -size +100M -exec gzip {} \; 2>/dev/null || true
            
            # Remove old log files (older than 30 days)
            find logs/ -name "*.log.gz" -mtime +30 -delete 2>/dev/null || true
            
            # Clean up old backup files (keep only 5 most recent)
            if [ -d "backups" ]; then
              echo "[CLEANUP] Managing backup retention..."
              cd backups 2>/dev/null && {
                # Remove backups older than 7 days
                find . -name "pre-deploy-*" -mtime +7 -exec rm -rf {} \; 2>/dev/null || true
                
                # Ensure we keep at least 5 most recent backups
                ls -dt pre-deploy-* 2>/dev/null | tail -n +6 | xargs rm -rf 2>/dev/null || true
                
                echo "[INFO] Backup cleanup completed"
                ls -la | head -10
              }
              cd ..
            fi
            
            # Docker system overview after cleanup
            echo "[INFO] Docker system usage after cleanup:"
            \$USE_SUDO docker system df
            
            # File system cleanup
            echo "[CLEANUP] File system cleanup..."
            
            # Remove temporary files
            find . -name "*.tmp" -delete 2>/dev/null || true
            find . -name "*.temp" -delete 2>/dev/null || true
            find . -name ".DS_Store" -delete 2>/dev/null || true
            find . -name "Thumbs.db" -delete 2>/dev/null || true
            
            # Clean up npm cache if it exists
            if [ -d "src/fe/nuxt/.nuxt" ]; then
              echo "[CLEANUP] Cleaning Nuxt build cache..."
              rm -rf src/fe/nuxt/.nuxt 2>/dev/null || true
            fi
            
            # Clean up .NET build artifacts
            find src/be -name "bin" -type d -exec rm -rf {} + 2>/dev/null || true
            find src/be -name "obj" -type d -exec rm -rf {} + 2>/dev/null || true
            
            # Set appropriate permissions for runtime
            echo "[SECURITY] Setting appropriate file permissions..."
            
            # Secure configuration files
            chmod 600 .env 2>/dev/null || true
            
            # Secure script files
            find . -name "*.sh" -exec chmod 755 {} \; 2>/dev/null || true
            
            # Secure log directories
            chmod -R 755 logs/ 2>/dev/null || true
            chmod -R 755 uploads/ 2>/dev/null || true
            
            # Remove Docker temp config
            rm -f /tmp/docker_config 2>/dev/null || true
            
            # Final disk usage report
            echo "[INFO] Final disk usage report:"
            df -h .
            
            # Final memory report
            echo "[INFO] Final memory usage:"
            free -h
            
            # Service status summary
            echo "[STATUS] Final service status summary:"
            \$USE_SUDO docker compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}" | head -20
            
            echo "[SUCCESS] Post-deployment cleanup completed successfully"
          EOF
        shell: bash
        
      - name: "[18/18] Send Discord enhanced success/failure notification"
        if: success() || failure()
        uses: appleboy/discord-action@v1.2.0
        with:
          webhook_url: ${{ secrets.DISCORD_WEBHOOK_URL }}
          message: |
            ${{ job.status == 'success' && '✅ **TiHoMo TrueNAS Deployment THÀNH CÔNG!**' || '❌ **TiHoMo TrueNAS Deployment THẤT BẠI!**' }}
            
            📊 **Deployment Information:**
            • **Status:** `${{ job.status == 'success' && 'SUCCESS' || 'FAILED' }}`
            • **Environment:** `${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || github.ref_name == 'staging' && 'staging' || 'development') }}`
            • **Branch:** `${{ github.ref_name }}`
            • **Trigger:** `${{ github.event_name == 'workflow_dispatch' && 'Manual' || 'Automatic' }}`${{ github.event_name == 'workflow_dispatch' && inputs.force_rebuild == true && ' (Force Rebuild)' || '' }}
            • **Commit:** `${{ github.sha }}`
            • **Deploy Time:** `$(date -u +"%Y-%m-%d %H:%M:%S UTC")`
            
            🔗 **Service URLs:**
            • **Frontend:** `http://<TRUENAS_IP>:${{ vars.FRONTEND_PORT || '3500' }}`
            • **API Gateway:** `http://<TRUENAS_IP>:${{ vars.GATEWAY_PORT || '5000' }}`
            • **Monitoring:** `http://<TRUENAS_IP>:${{ vars.GRAFANA_PORT || '3002' }}`
            • **RabbitMQ:** `http://<TRUENAS_IP>:${{ vars.RABBITMQ_MANAGEMENT_PORT || '15672' }}`
            • **pgAdmin:** `http://<TRUENAS_IP>:${{ vars.PGADMIN_PORT || '8081' }}`
            
            🏗️ **Infrastructure Status:**
            ${{ job.status == 'success' && '
            • **Frontend (Nuxt 3):** 🟢 Running
            • **API Gateway (Ocelot):** 🟢 Active
            • **Identity API:** 🟢 Healthy
            • **CoreFinance API:** 🟢 Operational
            • **PostgreSQL Cluster:** 🟢 Connected
            • **Redis Cache:** 🟢 Available
            • **RabbitMQ:** 🟢 Message Queue Active
            • **Monitoring Stack:** 🟢 Metrics Collecting
            ' || '
            • **System Status:** 🔴 Deployment Issues Detected
            • **Services:** ⚠️ Some services may not be running
            • **Databases:** ❓ Connection status unknown
            • **Monitoring:** 🔴 Limited visibility
            ' }}
            
            🛡️ **Security & Quality:**
            • **SSH Security:** Enhanced with proper host validation
            • **Image Scanning:** Trivy security checks performed
            • **Backup Strategy:** Pre-deployment backup created
            • **Health Checks:** ${{ job.status == 'success' && 'Comprehensive validation passed' || 'Issues detected during validation' }}
            
            ⚡ **Performance Metrics:**
            • **Deployment Strategy:** Rolling deployment (zero downtime)
            • **Build Strategy:** ${{ github.event_name == 'workflow_dispatch' && inputs.force_rebuild == true && 'Force rebuild (no cache)' || 'Smart caching enabled' }}
            • **Resource Management:** Monitored and validated
            • **Integration Tests:** ${{ job.status == 'success' && 'API communication verified' || 'Tests may have failed' }}
            
            ${{ job.status == 'success' && '🎉 **Deployment successful - system ready for use!**' || '🚨 **Action required - check logs for details**' }}
            
            [📋 View Detailed Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

      - name: "[TIMEOUT] Send Discord timeout notification"
        if: cancelled()
        uses: appleboy/discord-action@v1.2.0
        with:
          webhook_url: ${{ secrets.DISCORD_WEBHOOK_URL }}
          message: |
            ⏰ **TiHoMo Deployment TIMEOUT (> 30 phút)!**
            
            📊 **Timeout Information:**
            • **Branch:** `${{ github.ref_name }}`
            • **Environment:** `${{ github.event_name == 'workflow_dispatch' && inputs.environment || (github.ref_name == 'master' && 'production' || github.ref_name == 'develop' && 'development' || github.ref_name == 'staging' && 'staging' || 'development') }}`
            • **Trigger:** `${{ github.event_name == 'workflow_dispatch' && 'Manual Run' || 'Automatic' }}`
            • **Force Rebuild:** `${{ github.event_name == 'workflow_dispatch' && inputs.force_rebuild || 'false' }}`
            • **Duration:** > 30 minutes (auto-cancelled)
            
            🔍 **Possible Causes:**
            • **Docker Build:** Image building taking too long
            • **Network Issues:** Slow connectivity to TrueNAS
            • **Resource Constraints:** TrueNAS server overloaded  
            • **Database Init:** PostgreSQL initialization timeout
            • **Security Scanning:** Trivy scanning taking excessive time
            • **Health Checks:** Services not starting within expected time
            
            🔧 **Recommended Actions:**
            1. Check TrueNAS server resources (CPU, Memory, Disk)
            2. Verify network connectivity to TrueNAS
            3. Review recent changes that might cause build issues
            4. Consider running with `force_rebuild: false` to use cache
            5. Check if manual intervention needed on TrueNAS
            
            ⚠️ **System Status Unknown** - Manual verification required
            
            [📋 View Deployment Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
